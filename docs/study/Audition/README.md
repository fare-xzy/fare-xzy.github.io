# Audition Summary

## Basic
1. 多态三要素：继承、重写、父类引用指向子类对象
   ```
   举例:
   Father f = new Child()
   ```
2. 重写和重载：
   ![image](./../../../pic/Audition/重写和重载.png)
3. 抽象类和接口：
    1. 抽象类可以有构造方法，接口中不能有构造方法。
    2. 抽象类中可以有普通成员变量，接口中没有普通成员变量
    3. 抽象类中可以包含非抽象的普通方法，接口中的所有方法必须都是抽象的，不能有非抽象的普通方法。
    4. 抽象类中的抽象方法的访问类型可以是public，protected和（默认类型,虽然eclipse下不报错，但应该也不行），但接口中的抽象方法只能是public类型的，并且默认即为public abstract类型。
    5. 抽象类中可以包含静态方法，接口中不能包含静态方法
    6. 抽象类和接口中都可以包含静态成员变量，抽象类中的静态成员变量的访问类型可以任意，但接口中定义的变量只能是public static final类型，并且默认即为public static final类型。
    7. 一个类可以实现多个接口，但只能继承一个抽象类
4. 泛型通配符super和extends的区别：（[Java示例](./../../../../../java/src/main/java/com/xzy/java/other/generic/GenericTest.java)）
    1. ? 表示通配符类型
    2. <? extends T> 既然是extends，就是表示泛型参数类型的上界，说明参数的类型应该是T或者T的子类。
    3. <? super T> 既然是super，表示的则是类型的下界，说明参数的类型应该是T类型的父类，一直到object
    4. 总结：
        * extends 可用于的返回类型限定，不能用于参数类型限定。
        * super 可用于参数类型限定，不能用于返回类型限定。
        * 希望只取出，不插入，就使用? extends
        * 希望只插入，不取出，就使用? super
        * 希望，即能插入，又能取出，就不要用通配符？
5. String 类为什么设计为final?
    * 主要是为了”安全性“和”效率“的缘故
        * final修饰的类或方法，被final修饰的类不能被继承，即它不能拥有自己的子类，被final修饰的方法不能被重写， final修饰的变量，无论是类属性、对象属性、形参还是局部变量，都需要进行初始化操作。
        * 那么为什么保证String不可变呢,因为只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变
        * String就被设计成一个不变类，这样有助于共享，提高性能。可以将字符串对象保存在字符串常量池中以供与字面值相同字符串对象共 享。如果String对象是可变的，那就不能这样共享，因为一旦对某一个String类型变量引用的对象值改变，将同时改变一起共享字符串对象的其他 String类型变量所引用的对象的值 
    * 优点：
        * 因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。
        * 因为字符串是不可变的，所以在它创建的时候HashCode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。
6. String StringBuffer StringBuilder 在进行字符串操作时的效率
    * 耗时时长 String > StringBuffer > StringBuilder
        * 1、StringBuffer和StringBuilder的唯一区别就是StringBuffer中加了同步，所以StringBuffer慢于StringBuilder
        * 2、String 内部对字字符串的操作也是通过哦StringBuilder实现的，并且每次操作完成后都会条用toString方法转成字符串对象，并且每次操作都要重新new StringBuilder
    * 反编译指令 javap -c *.class 可以看出实现原理[汇编指令](https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5)
## Thread
1. 锁的分类
    1. 按照锁的性质分类：
        1. 公平锁/非公平锁
            1. 公平锁是指多个线程按照申请锁的顺序来获取锁
            2. 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象
            3. 举例：
                * 对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大
                * 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁
        2. 乐观锁/悲观锁：看待并发同步的态度
            1. 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题
            2. 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的
            3. 悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升
            4. 举例：
                * 悲观锁在Java中的使用，就是利用各种锁。
                * 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。
        * 独享锁/共享锁：是否被多个线程所持有
            1. 独享锁是指该锁一次只能被一个线程所持有
            2. 共享锁是指该锁可被多个线程所持有
            3. 举例：
                * Java ReentrantLock而言，其是独享锁
                * ReadWriteLock，其读锁是共享锁，其写锁是独享锁
                * Synchronized而言，当然是独享锁
        * 互斥锁/读写锁：具体的实现。互斥锁在java中具体实现是ReentrantLock;读写锁在java中具体实现是ReentrantReadWriteLock
        * 可重入锁：
            1. 又称递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁
            2. 可重入锁的一个好处是可一定程度避免死锁。
            3. 举例：
                * Java ReentrantLock
                * Synchronized
            
    2. 按照设计方案分类：
        * 自旋锁/自适应自旋锁：
            1. 自旋锁:是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁
                * 优点是：自旋等待本身可以避免线程切换的开销。
                * 缺点是：自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的
            2. 自适应锁：自适应意味着自旋的时间不再固定了，而是由前 一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。
                * 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长时间，比如100个循环
                * 如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源
        * 锁粗化/锁消除：是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除/减少没必要的加锁
        * 偏向锁/轻量级锁/重量级锁：
            1. 锁的状态，并且这对synchronized
            2. 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
            3. 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
            4. 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。
        * 分段锁：ConcurrentHashMap并发实现
            * 其实是一种锁的设计，并不是具体的一种锁，通过分段锁的形式实现高效的并发操作
            * 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
            * 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作
2. [多线程相关内容]()
## JVM
![image](./../../../pic/Audition/1.8JVM模型.png)
1. JVM classLoader机制
   * 
## DesignPatterns


## NetWork

## Databases

### Redis
1. redis持久化机制
    * Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。实现：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。
    1. RDB：
        * 是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）
    2. AOF：
        * Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。
    3. 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。生产环境可以同时开启两种方式，优先使用AOF恢复，同时RDB可以用作冷备。并且当AOF日志文件出现异常时还可以通过RDB恢复
2. 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题
    1. 缓存雪崩：可以简单的理解为：由于原有缓存失效，新缓存未到期间
        * (例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃
        * 解决：大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开。
    2. 缓存穿透：缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。
        * 解决办法-1，[布隆过滤器](#布隆过滤器)
        * 解决办法-2，查询数据库如果不存在则在redis临时存储一个标识（设置短失效时间），使得下一次请求进来时可以先通过redis判断是否数据存在
        * 缓存穿透和缓存击穿的区别：
            * 定义：缓存击穿：指一个key非常热点，大并发集中对这个key进行访问，当这个key在失效的瞬间，仍然持续的大并发访问就穿破缓存，转而直接请求数据库。
            * 解决：在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key
    3. 缓存预热：缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
        * 解决办法-1，直接写个缓存刷新页面，上线时手工操作下
        * 解决办法-2，数据量不大，可以在项目启动的时候自动进行加载
        * 解决办法-3，定时刷新缓存
    4. 缓存更新：除了缓存服务器自带的缓存失效策略之外（[Redis默认的有6中策略可供选择](#Redis缓存数据淘汰策略)），我们还可以根据具体的业务需求进行自定义的缓存淘汰
    5. 缓存降级：当访问量激增、服务出现问题时。系统可以将一些不关键内容进行降级。也就是停用或者假停用或者延时处理。目的是为了在大访问量是核心服务可以正常进行，即使是有损的。
        * 举例：阿里双十一，0点以后加入购物车后不可以进行地址修改操作
3. 热点数据和冷数据
    1. 热点数据是使用频率很高或者修改频率很高，需要用缓存在处理查询或者修改该数据。例如：点赞数，收藏数，分享数
    2. 冷数据就使用频率很低的数据
4. Memcache与Redis的区别都有哪些？
    1. 存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据
    2. 数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储
    3. 使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
    4. value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。
    5. redis的速度比memcached快很多
    6. Redis支持数据的备份，即master-slave模式的数据备份。
5. 单线程的redis为什么这么快
    1. 纯内存操作
    2. 单线程操作避免了繁琐的上下文操作
    3. 采用了[非阻塞I/O多路复用](#阻塞I/O、非阻塞I/O和I/O多路复用)机制
6. redis的数据类型，以及每种数据类型的使用场景
    1. 字符串（Strings）
        * 字符串是一种最基本的Redis值类型。Redis字符串是二进制安全的，这意味着一个Redis字符串能包含任意类型的数据，例如： 一张JPEG格式的图片或者一个序列化的Ruby对象
        * 一个字符串类型的值最多能存储512M字节的内容。
    2. 列表（Lists）
        * Redis列表是简单的字符串列表，按照插入顺序排序。 你可以添加一个元素到列表的头部（左边）或者尾部（右边）。
        * 一个列表最多可以包含232-1个元素（4294967295，每个表超过40亿个元素）。
    3. 集合（Sets）
        * Redis集合是一个无序的字符串合集。你可以以O(1) 的时间复杂度（无论集合中有多少元素时间复杂度都为常量）完成 添加，删除以及测试元素是否存在的操作。
        * Redis集合有着不允许相同成员存在的优秀特性。向集合中多次添加同一元素，在集合中最终只会存在一个此元素。实际上这就意味着，在添加元素前，你并不需要事先进行检验此元素是否已经存在的操作。
        * 一个集合最多可以包含232-1个元素（4294967295，每个集合超过40亿个元素）。
    4. 哈希（Hashes）
        * Redis Hashes是字符串字段和字符串值之间的映射，所以它们是完美的表示对象（eg:一个有名，姓，年龄等属性的用户）的数据类型。
        * 一个拥有少量（100个左右）字段的hash需要 很少的空间来存储，所有你可以在一个小型的 Redis实例中存储上百万的对象。
        * 一个hash最多可以包含232-1 个key-value键值对（超过40亿）。
    5. 有序集合（Sorted sets）
        * Redis有序集合和Redis集合类似，是不包含 相同字符串的合集。它们的差别是，每个有序集合 的成员都关联着一个评分，这个评分用于把有序集 合中的成员按最低分到最高分排列。
        * 使用有序集合，你可以非常快地（O(log(N))）完成添加，删除和更新元素的操作。
    6. Bit arrays (或者说 simply bitmaps) 
        * 通过特殊的命令，你可以将 String 值当作一系列 bits 处理：可以设置和清除单独的 bits，数出所有设为 1 的 bits 的数量，找到最前的被设为 1 或 0 的 bit 
        * 优势：
            1.基于最小的单位bit进行存储，所以非常省空间。
            2.设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的。
            3.二进制数据的存储，进行相关计算的时候非常快。
            4.方便扩容
        * 限制：
            redis中bit映射被限制在512MB之内，所以最大是2^32位。建议每个key的位数都控制下，因为读取时候时间复杂度O(n)，越大的串读的时间花销越多
        * 使用场景
            1. 通常用于量很大，value很小的情况
            2. 一种是某一用户的横向扩展，即此个key值中记录这当前用户的各种状态值，允许无限扩展(2^32内)(例如：某段视频的视频属性)
            3. 一种是某一用户的纵向扩展，即每个key只记录当前业务属性的状态，每个uid当作bit位来记录信息(用户超过2^32内需要分片存储)（例如：用户签到、活跃度、在线情况）
    7. HyperLogLogs
        * 这是被用于估计一个 set 中元素数量的概率性的数据结构，用于对唯一事物进行计数
        * HyperLogLog 提供不精确的去重计数方案，标准误差大概在 0.81%
    8. Streams（redis 5以后）
        * 可以把streams当做MQ，甚至可以把streams当做kafka
        * 重要命令：
            1. XADD： XADD key ID field string [field string …]
                1. key：的含义就是同一类型streams的名称；
                2. ID: streams中entry的唯一标识符，如果执行XADD命令时，传入星号（*），那么，ID会自动生成，且自动生成的ID会在执行XADD后返回，默认生成的ID格式为millisecondsTime+sequenceNumber，即当前毫秒级别的时间戳加上一个自增序号值，例如"1540013735401-0"。并且执行XADD时，不接受少于或等于上一次执行XADD的ID，否则会报错：ERR The ID specified in XADD is equal or smaller than the target stream top item；
                3. field&string：接下来就是若干组field string。可以把它理解为表示属性的json中的key-value
            2. Streams 的三种查询模式
                1. 范围查询（XRANGE[正序]、XREVRANGE[逆序]）：因为streams的每个entry，其默认生成的ID是基于时间且递增的；
                    * 用法：XRANGE key start end [COUNT count]
                    * 用来返回streams某个顺序范围下的元素，start参数是更小的ID，end参数是更大的ID。有两个特殊的ID用符号"-"和"+"表示，符号"-"表示最小的ID，符号"+"表示最大的ID
                2. 监听模式（XREAD）：类比linux中的tailf命令，实时接收新增加到streams中的entry（也有点像一个消息系统，事实上笔者认为它就是借鉴了kafka）；
                    * 作用是返回streams中从来没有读取的，且比参数ID更大的元素
                3. 消费者组（XREADGROUP）：即Consumer Groups，特殊的监听模式。从一个消费者的角度来看streams，一个streams能被分区到多个处理消息的消费者，对于任意一条消息，同一个消费者组中只有一个消费者可以处理（和kafka的消费者组完全一样）。这样还能够横向扩容消费者，从而提升处理消息的能力，而不需要只让把让一个消费者处理所有消息。
                    * 特点：
                        1. 同一个消息不会被投递到一个消费者组下的多个消费者，只可能是一个消费者。
                        2. 同一个消费者组下，每个消费者都是唯一的，通过大小写敏感的名字区分。
                        3. 消费者组中的消费者请求的消息，一定是新的，从来没有投递过的消息。
                        4. 消费一个消息后，需要用命令（XACK）确认，意思是说：这条消息已经给成功处理。正因为如此，当访问streams的历史消息时，每个消费者只能看到投递给它自己的消息。
7. Redis内部结构
    1. dict 本质上是为了解决算法中的查找问题（Searching）是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。 本质上是为了解决算法中的查找问题（Searching）
    2. sds sds就等同于char * 它可以存储任意二进制数据，不能像C语言字符串那样以字符’\0’来标识字符串的结 束，因此它必然有个长度字段。
    3. skiplist （跳跃表） 跳表是一种实现起来很简单，单层多指针的链表，它查找效率很高，堪比优化过的二叉平衡树，且比平衡树的实现，
    4. quicklist  是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。
    5. ziplist 压缩表 ziplist是一个编码后的列表，是由一系列特殊编码的连续内存块组成的顺序型数据结构
8. Redis 为什么是单线程的
    * 官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）Redis利用队列技术将并发访问变为串行访问
9. Redis 的优点
    1. 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
    2. 支持丰富数据类型，支持string，list，set，sorted set，hash
    3. 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行，对redis的操作都是具有原子性的,是线程安全的操作,你不用考虑并发问题,redis内部已经帮你处理好并发的问题了。
    4. 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除、
10. 如何解决redis的并发竞争key问题
    * 同时有多个子系统去set一个key。这个时候要注意什么呢？ 不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋
    1. 如果对这个key操作，不要求顺序： 准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可
    2. 如果对这个key操作，要求顺序： 分布式锁+时间戳。 假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。
    3. 利用队列，将set方法变成串行访问也可以redis遇到高并发，如果保证读写key的一致性
11. redis的集群方案
    1. 主从模式：当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。
        * 优点：
            1. 高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切换，从库提升为主库提供服务，保证服务平稳运行;另一方面，开启数据持久化功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题;
            2. 读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。
        * 缺点：
            1. 故障恢复复杂，如果没有 RedisHA 系统(需要开发)，当主库节点出现故障时，需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要让其它从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐
            2. 主库的写能力受到单机的限制，可以考虑分片
            3. 主库的存储能力受到单机的限制，可以考虑 Pika
    2. 集群：使用集群，只需要将每个数据库节点的cluster-enable配置打开即可。每个集群中至少需要三个主数据库才能正常运行。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容。
        * 优点：
            1. 无中心架构;
            2. 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布;
            3. 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除;
            4. 高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升;
            5. 降低运维成本，提高系统的扩展性和可用性。
        * 缺点：
            1. Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”
            2. 节点会因为某些原因发生阻塞(阻塞时间大于 clutser-node-timeout)，被判断下线，这种 failover 是没有必要的.
            3. 数据通过异步复制，不保证数据的强一致性.
            4. 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况
            5. Slave 在集群中充当“冷备”，不能缓解读压力，当然可以通过 SDK 的合理设计来提高 Slave 资源的利用率
            6. Key 批量操作限制，如使用 mset、mget 目前只支持具有相同 slot 值的 Key 执行批量操作。对于映射为不同 slot 值的 Key 由于 Keys 不支持跨 slot 查询，所以执行 mset、mget、sunion 等操作支持不友好
            7. 不支持多数据库空间，单机下的 redis 可以支持到 16 个数据库，集群模式下只能使用 1 个数据库空间，即 db 0
            8. 避免产生 hot-key，导致主库节点成为系统的短板
            9. 避免产生 big-key，导致网卡撑爆、慢查询等
            10. 重试时间应该大于 cluster-node-time 时间
    3. 哨兵模式：实现自动化的系统监控和故障恢复功能，哨兵的作用就是监控redis主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。全量存储
        * 优点：
            1. 能够解决 Redis 主从模式下的高可用切换问题;
            2. 很方便实现 Redis 数据节点的线形扩展，轻松突破 Redis 自身单线程瓶颈，可极大满足 Redis 大容量或高性能的业务需求;
            3. 可以实现一套 Sentinel 监控一组 Redis 数据节点或多组数据节点;
        * 缺点：
            1. 部署相对 Redis 主从模式要复杂一些，原理理解更繁琐;
            2. 资源浪费，Redis 数据节点中 slave 节点作为备份节点不提供服务;
            3. Redis Sentinel 主要是针对 Redis 数据节点中的主节点的高可用切换，对 Redis 的数据节点做失败判定分为主观下线和客观下线两种，对于 Redis 的从节点有对节点做主观下线操作，并不执行故障转移。
            4. 不能解决读写分离问题，实现起来相对复杂。
12. Redis 常见性能问题和解决方案
    1. Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件
    2. 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次
    3. 为了主从复制的速度和连接的稳定性， Master 和 Slave 最好在同一个局域网内
    4. 尽量避免在压力很大的主库上增加从库
    5. 主从复制不要用图状结构，用单向链表结构更为稳定，即： Master <- Slave1 <- Slave2 <-Slave3…            
13. Redis线程模型
    * Redis内部使用文件事件处理器，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型，它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理
    * redis线程模型分为四部分：
        1. 套接字
        2. IO多路复用程序
        3. 文件时间分派器
        4. 事件处理器（包括：连接应答处理器、命令请求处理器、命令回复处理器）
    * 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用 程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理
    ![](../../../pic/Audition/Redis线程模型.png)
14. 为什么Redis的操作是原子性的，怎么保证原子性的
    * 对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。
    * Redis的操作之所以是原子性的，是因为Redis是单线程的。
    * Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性
# Other
## 布隆过滤器
1. 本质上为一种概率型数据结构，特点是高效的插入和查询可以用来告诉你 “某样东西一定不存在或者可能存在”,相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。传统布隆过滤器不支持删除操作
2. 原理：
    * 存储：当数据存储时会对其使用多个hash函数进行hash计算，返回的内容指向一个bit数组的多个个位置。如果有多个数据计算hash后指向的bit位置相同，将会对该位置进行覆盖操作。
    * 查询时如果计算hash后查找bit数组中包含对应hash值，则说明该数据集可能包含该数据。如果计算的hash值中有一个或者多个不存在与bit数组中，则证明肯定不包含该数据
3. 选择哈希函数个数和布隆过滤器长度
    * 很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高
    
    ![](../../../pic/Audition/布隆过滤器曲线图.png)
    * 选择合适的hash函数个数以及布隆过滤器长度
    * k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率。
    
    ![](../../../pic/Audition/Hash函数个数与过滤器长度计算.png)
4. 最佳实践：
    * 常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。
    * 另外，既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。
    * Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用
## Redis缓存数据淘汰策略
1. 为什么要有种种过期策略：
    * redis是单线程，收割时间也会占用线程处理时间，如果收割过于频繁，会导致读写出现卡顿
2. 主库过期策略：
    1. 定时扫描,首先将每个设置了过期时间的key放到一个独立的hash中，默认每秒定时遍历这个hash而不是整个空间：并不会遍历所有的key，采用一种简单的贪心策略
        1. 从过期key字典中，随机找20个key。
        2. 删除20个key中过期的key
        3. 如果2中过期的key超过1/4，则重复第一步
        4. 每次处理的时间都不会25ms
        5. 如果有大量的key在同一时间段内过期，就会造成数据库的集中访问，就是缓存雪崩！
    2. 惰性策略
        1. 客户端访问的时候，会对这个key的过期时间进行检查，如果过期了就立即删除。惰性策略是对定时策略的补充，因为定时策略不会删除所有过期的key
3. 从库过期策略：
    * redis不会扫描从库，删除主库数据的时候，在aof文件里生成一条del指令，在主从同步的时候，从库会执行这条指令，删除过期key。所以[集群分布式锁算法](#集群分布式锁算法)的漏洞就是这样产生的
4. 常见的缓存失效策略：
    1. FIFO，first in first out，最先进入缓存的数据在缓存空间不够情况下(超出最大元素限制时)会被首先清理出去
    2. LFU， Less Frequently Used，一直以来最少被使用的元素会被被清理掉。这就要求缓存的元素有一个hit 属性，在缓存空间不够得情况下,hit 值最小的将会被清出缓存。
    3. LRU，Least Recently Used，最近最少使用的，缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。
5. 缓存更新策略：
    1. Cache aside：
        * 读取：
        * 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
        * 命中：应用程序从cache中取数据，取到后返回。
        * 更新：先把数据存到数据库中，成功后，再让缓存失效。
    2. Read Through
        * Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。
    3. Write Through
        * Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）
    4. Write Behind Caching Pattern
        * Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
        * 带来的问题就是此时数据不是强一致性的
6. 缓存淘汰机制
    * 如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了---走内存淘汰机制
        1. volatile-lru：从已设置过期时间的数据中挑选最近最少使用的数据淘汰；
        2. volatile-ttl：从已设置过期时间的数据中挑选将要过期的数据淘汰；
        3. volatile-random：从已设置过期时间的数据中任意选择数据淘汰；
        4. allkeys-lru：从数据集中挑选最近最少使用的数据淘汰；
        5. allkeys-random：从数据集中任意选择数据淘汰；
        6. no-enviction（驱逐）：禁止驱逐数据


3### 集群分布式锁算法
* RedLock算法
    1. 原理：
        1. 获取当前时间（单位是毫秒）。
        2. 轮流用相同的key和随机值在N个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点。
        3. 客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁（在这里是3个），而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了。
        4. 如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。
        5. 如果锁获取失败了，不管是因为获取成功的锁不超过一半（N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁。
    2. 案例：[(Redisson)](https://github.com/redisson/redisson)
## I/O
1. 阻塞 I/O（blocking IO）  BIO
    * 在linux中，默认情况下所有的socket都是blocking
    ![](../../../pic/Audition/阻塞IO.png)
    * 顺序执行并且单线程，如果没有内容返回则会一直等待
2. 非阻塞 I/O（nonblocking IO）
    * linux下，可以通过设置socket使其变为non-blocking
    ![](../../../pic/Audition/非阻塞IO.png)
    * 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。
3. I/O 多路复用（ IO multiplexing） NIO
    * IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程
    ![](../../../pic/Audition/IO多路复用.png)
    * 也就是使用少量线程在去轮训Selector上面注册的事件，当有就绪的时间产生则进行处理。
    * 注意，使用NIO != 高性能，当连接数<1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。如果放到线上环境，网络情况在有时候并不稳定的情况下，这种基于I/O复用技术的NIO的优势就是传统BIO不可同比的了
4. 异步 I/O（asynchronous IO） AIO
    * 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。
    ![](../../../pic/Audition/异步IO.png)
    * AIO能够胜任那些重量级，读写过程长的任务